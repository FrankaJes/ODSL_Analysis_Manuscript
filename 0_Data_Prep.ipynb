{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "This file concatenates data from the different models. We create the following files:\n",
    "- CMIP5_time_series.nc\n",
    "- CMIP5_time_series_smoothed.nc\n",
    "- CMIP6_time_series.nc\n",
    "- CMIP6_time_series_smoothed.nc\n",
    "- CMIP5_spatial_zos.nc\n",
    "- CMIP6_spatial_zos.nc\n",
    "- CMIP5_spatial_MLD.nc\n",
    "- CMIP5_spatial_MLD_mlotst.nc\n",
    "- CMIP5_spatial_MLD_Heuzé.nc\n",
    "- CMIP6_spatial_MLD.nc\n",
    "- CMIP6_spatial_MLD_mlotst.nc\n",
    "- CMIP6_spatial_MLD_Heuzé.nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xesmf as xe\n",
    "\n",
    "import statsmodels.api as sm            # to build a LOWESS model\n",
    "from scipy.interpolate import interp1d  # for interpolation of new data points\n",
    "lowess = sm.nonparametric.lowess\n",
    "\n",
    "import dask.config as dc\n",
    "dc.set(**{'array.slicing.split_large_chunks': True});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select directories\n",
    "original_data_dir = 'Raw_Data/'\n",
    "write_data_to_dir = 'Data/'\n",
    "\n",
    "standard_reference_period = [1900, 1950]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial zos\n",
    "In this section, we create:\n",
    "- CMIP5_spatial_zos.nc\n",
    "- CMIP6_spatial_zos.nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_zos_ds(data_dir, mip, sce):\n",
    "    \"\"\"\n",
    "    Read both historical and scenario datasets, select the intersecting \n",
    "    models and concatenate the two datasets\n",
    "    \"\"\"\n",
    "    \n",
    "    hist_ds = xr.open_mfdataset(\n",
    "        f'{data_dir}/{mip}_zos_historical/{mip}_zos_historical_*.nc')\n",
    "    sce_ds = xr.open_mfdataset(\n",
    "        f'{data_dir}/{mip}_zos_{sce}/{mip}_zos_{sce}_*.nc')\n",
    "\n",
    "    model_intersection = list(set(hist_ds.model.values) & \n",
    "                              set(sce_ds.model.values))\n",
    "    model_intersection.sort()\n",
    "   \n",
    "    tot_ds = xr.concat([hist_ds, sce_ds], 'time').sel(model = model_intersection, time = slice(1900, 2101))\n",
    "\n",
    "    return tot_ds\n",
    "\n",
    "\n",
    "def concat_zos_data(data_dir, mip, ref_start, ref_end):\n",
    "    \"\"\"\n",
    "    Concatenate different scenarios and set reference period.\n",
    "    \"\"\"\n",
    "    \n",
    "    scenarios_dic = {'cmip5': [ 'rcp26',  'rcp45',  'rcp85'],\n",
    "                     'cmip6': ['ssp126', 'ssp245', 'ssp585']}\n",
    "    \n",
    "    zos_mip = [[],[],[]]\n",
    "    \n",
    "    for i, sce in enumerate(scenarios_dic[mip]):\n",
    "\n",
    "        # Read data for specific scenario\n",
    "        zos = read_zos_ds(data_dir, mip, sce)\n",
    "\n",
    "        # Set right reference period and select North Eastern region of the North Atlantic\n",
    "        zos = zos - zos.sel(time=slice(ref_start, ref_end)).mean(dim='time')\n",
    "        zos = zos.sel(lat=slice(15,82), lon=slice(-45,60))\n",
    "        \n",
    "        # Rename variable and add scenario to dimensions\n",
    "        zos = zos.rename({'CorrectedReggrided_zos':'spatial_zos'})\n",
    "        zos = zos.assign_coords({'scenario': sce})\n",
    "\n",
    "        # Fill in overarching list\n",
    "        zos_mip[i] = zos \n",
    "    \n",
    "    # Concatenate different scenarios\n",
    "    zos_mip = xr.concat(zos_mip, dim='scenario')\n",
    "\n",
    "    return zos_mip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CMIP5_spatial_zos = concat_zos_data(original_data_dir, 'cmip5', 1900, 1950)\n",
    "CMIP6_spatial_zos = concat_zos_data(original_data_dir, 'cmip6', 1900, 1950)\n",
    "\n",
    "CMIP5_spatial_zos.to_netcdf(write_data_to_dir+'CMIP5_spatial_zos.nc')\n",
    "CMIP6_spatial_zos.to_netcdf(write_data_to_dir+'CMIP6_spatial_zos.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CMIP5_spatial_zos.close()\n",
    "CMIP6_spatial_zos.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time series\n",
    "In this section, we create:\n",
    "- CMIP5_time_series.nc\n",
    "- CMIP5_time_series_smoothed.nc\n",
    "- CMIP6_time_series.nc\n",
    "- CMIP6_time_series_smoothed.nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to read GSAT\n",
    "def select_tglob_cmip6_files(data_dir, sce, verbose=False):\n",
    "    '''The file name of cmip6 tglob files from the climate explorer contains \n",
    "    some information about the variant as well. Only one needs to be chosen \n",
    "    and the name of the model needs to be cleaned.'''\n",
    "    \n",
    "    path = f'{data_dir}global_tas_mon_*_{sce}_000.dat'\n",
    "    files  = glob.glob(path)\n",
    "\n",
    "    model_names = []\n",
    "    for f in files:\n",
    "        file_name_no_path = f.split('/')[-1]\n",
    "        model_name = file_name_no_path.split('_')[3]\n",
    "        model_names.append(model_name)\n",
    "\n",
    "    model_names.sort()\n",
    "\n",
    "    clean_model_names = []\n",
    "    lp_list = []\n",
    "    for m in model_names:\n",
    "        lp = m.split('-')[-1]\n",
    "        lp_list.append(lp)\n",
    "        if lp in ['f2', 'p2', 'p1', 'p3', 'f3']:\n",
    "            clean_model_names.append(m[:-3])\n",
    "        else:\n",
    "            clean_model_names.append(m)\n",
    "\n",
    "    df = pd.DataFrame({'model_names': model_names,\n",
    "                       'clean_model_names': clean_model_names,\n",
    "                       'fp': lp_list})\n",
    "\n",
    "    for m in df['clean_model_names']:\n",
    "        if (list(df['clean_model_names']).count(m) > 1):\n",
    "            fp_choice = df[df.clean_model_names==m]['fp']\n",
    "            ind = df[(df.fp!=fp_choice.iloc[0]) & (df.clean_model_names==m)].index\n",
    "            \n",
    "            if verbose:\n",
    "                print(f'Multiple variants of {m}')\n",
    "                print('Available variants')\n",
    "                print(fp_choice)\n",
    "                print(f'Choosing {fp_choice.iloc[0]}')\n",
    "                \n",
    "            df.drop(ind, inplace=True)\n",
    "\n",
    "    file_list = []\n",
    "    for m in df.model_names:\n",
    "        file_list.append(f'{data_dir}global_tas_mon_{m}_{sce}_000.dat')\n",
    "    \n",
    "    df['file_names'] = file_list\n",
    "    \n",
    "    return df\n",
    "\n",
    "def tglob_cmip(data_dir, mip, sce, start_date, ye, LowPass=False):\n",
    "    '''Read the text files of monthly temperature for each CMIP5 model and store\n",
    "    yearly averged values in an xarray DataArray.\n",
    "    Output data is in degree Kelvin'''\n",
    "    \n",
    "    #nb_y = ye-start_date+1\n",
    "    \n",
    "    if mip == 'CMIP5':\n",
    "        temp_data_dir = f'{data_dir}Tglobal_CMIP5/'\n",
    "        path = f'{temp_data_dir}global_tas_Amon_*_{sce}_r1i1p1.dat'\n",
    "        files = glob.glob(path)\n",
    "        print(files[1][39:-17])\n",
    "        model_names = [f[39:-17] for f in files]\n",
    "        df = pd.DataFrame({'clean_model_names': model_names, 'file_names': files})\n",
    "        \n",
    "    elif mip =='CMIP6':\n",
    "        temp_data_dir = f'{data_dir}Tglobal_CMIP6/'\n",
    "        df = select_tglob_cmip6_files(temp_data_dir, sce)\n",
    "        \n",
    "    else:\n",
    "        print(f'ERROR: Value of TEMP: {mip} not recognized')\n",
    "\n",
    "    \n",
    "    col_names = ['Year', 'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug',\n",
    "                 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        TEMP = pd.read_csv(df.file_names.iloc[i], \n",
    "                           comment='#', \n",
    "                           delim_whitespace=True,\n",
    "                           names=col_names)\n",
    "        TEMP = TEMP.set_index('Year')\n",
    "        TGLOBi = xr.DataArray(TEMP.mean(axis=1))\n",
    "        mod = df.clean_model_names.iloc[i]\n",
    "        TGLOBi = TGLOBi.expand_dims({'model':[mod]})\n",
    "\n",
    "        if i==0:\n",
    "            TGLOB = TGLOBi\n",
    "        else:\n",
    "            TGLOB = xr.concat([TGLOB, TGLOBi], dim='model')\n",
    "\n",
    "    TGLOB = TGLOB.rename({'Year':'time'})\n",
    "    TGLOB = TGLOB.sel(time=slice(start_date,ye))\n",
    "\n",
    "    if LowPass:\n",
    "        new_time = xr.DataArray( np.arange(start_date,ye+1), dims='time', \n",
    "                coords=[np.arange(start_date,ye+1)], name='time' )\n",
    "        fit_coeff = TGLOB.polyfit('time', 2)\n",
    "        TGLOB = xr.polyval(coord=new_time, coeffs=fit_coeff.polyfit_coefficients) \n",
    "\n",
    "    TGLOB.name = 'GSAT'\n",
    "    \n",
    "    return TGLOB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to read GMTSL\n",
    "def read_zostoga_ds(data_dir, mip, sce):\n",
    "    '''Read both historical and scenario datasets, select the intersecting \n",
    "    models and concatenate the two datasets'''\n",
    "    \n",
    "    hist_ds = xr.open_mfdataset(\n",
    "        f'{data_dir}/{mip}_zostoga/{mip}_zostoga_historical_*.nc')*100\n",
    "    sce_ds = xr.open_mfdataset(\n",
    "        f'{data_dir}/{mip}_zostoga/{mip}_zostoga_{sce}_*.nc')*100\n",
    "\n",
    "    model_intersection = list(set(hist_ds.model.values) & \n",
    "                              set(sce_ds.model.values))\n",
    "    model_intersection.sort()\n",
    "    tot_ds = xr.concat([hist_ds,sce_ds],'time').sel(model=model_intersection)\n",
    "    \n",
    "    return tot_ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to read AMOC\n",
    "\"\"\" \n",
    "Note that we have two groups of models:\n",
    "    - AMOC computed using stream function           (read_amoc_ds_using_streamfunction)\n",
    "    - AMOC computed using meridional velocities     (read_amoc_ds_using_velocities)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def read_amoc_ds_using_streamfunction(data_dir, mip, sce):\n",
    "    '''\n",
    "    Read both historical and scenario datasets, select the intersecting \n",
    "    models and concatenate the two datasets. \n",
    "    '''\n",
    "    \n",
    "    tot_ds = []\n",
    "    \n",
    "    # From mstmz to sverdrup \n",
    "    DF = 1026*10**6 \n",
    "    \n",
    "    if mip == 'cmip5':\n",
    "        variable_name = ['msftmyz']\n",
    "    elif mip == 'cmip6':\n",
    "        variable_name = ['msftmz','msftyz']\n",
    "    else:\n",
    "        print('mip is not recognized')\n",
    "        \n",
    "    for var in variable_name:\n",
    "        for reg in ['26N', '35N']:\n",
    "            hist_ds = xr.open_mfdataset(\n",
    "                f'{data_dir}/{mip}_amoc/{mip}_{var}_{reg}_historical_*.nc')\n",
    "            sce_ds = xr.open_mfdataset(\n",
    "                f'{data_dir}/{mip}_amoc/{mip}_{var}_{reg}_{sce}_*.nc')\n",
    "            \n",
    "            # CESM4 is in there twice, remove one\n",
    "            if sce == 'rcp45':\n",
    "                sce_ds = sce_ds.isel(model=[0,1,2,3,4,5,7,8,9,10,11])\n",
    "            \n",
    "            model_intersection = list(set(hist_ds.model.values) & set(sce_ds.model.values))\n",
    "            model_intersection.sort()\n",
    "            \n",
    "            full_ensemble = xr.concat([hist_ds,sce_ds],'time').sel(model=model_intersection)\n",
    "\n",
    "            # Model CNRM-CM5 is a factor 10**6 off - correct for that. \n",
    "            if mip == 'cmip5':\n",
    "                full_ensemble.loc[dict(model='CNRM-CM5')] = full_ensemble.sel(model='CNRM-CM5')['msftmyz'] * 10**6 \n",
    "\n",
    "            tot_ds.append(full_ensemble)\n",
    "\n",
    "    if mip == 'cmip5':\n",
    "        my26N, my35N = tot_ds\n",
    "        \n",
    "        \n",
    "        xr_my = xr.Dataset(\n",
    "            data_vars=dict(\n",
    "                AMOC26 = ([\"model\", \"time\"], my26N.msftmyz.values/DF),\n",
    "                AMOC35 = ([\"model\", \"time\"], my35N.msftmyz.values/DF),\n",
    "            ),\n",
    "            coords=dict(\n",
    "                model= my26N.model.values,\n",
    "                time = my26N.time.values,\n",
    "            ),\n",
    "            attrs=dict(description=\"Dataset with AMOC, zos data.\"),\n",
    "        )\n",
    "        AMOC = xr_my\n",
    "        \n",
    "    elif mip == 'cmip6':\n",
    "        m26N, m35N, y26N, y35N = tot_ds\n",
    "    \n",
    "        modsm = m26N.model.values\n",
    "        modsy = y26N.model.values\n",
    "    \n",
    "        overlap = np.sort(list(set(modsm)&set(modsy)))\n",
    "    \n",
    "        new_modsy = np.array([ele for ele in modsy if ele not in overlap])\n",
    "    \n",
    "        y26N = y26N.sel(model=new_modsy)\n",
    "        y35N = y35N.sel(model=new_modsy)\n",
    "    \n",
    "        xr_m = xr.Dataset(\n",
    "            data_vars=dict(\n",
    "                AMOC26 = ([\"model\", \"time\"], m26N.msftmz.values/DF),\n",
    "                AMOC35 = ([\"model\", \"time\"], m35N.msftmz.values/DF),\n",
    "            ),\n",
    "            coords=dict(\n",
    "                model= modsm,\n",
    "                time = m26N.time.values,\n",
    "            ),\n",
    "            attrs=dict(description=\"Dataset with AMOC, zos data.\"),\n",
    "        )\n",
    "    \n",
    "        xr_y = xr.Dataset(\n",
    "            data_vars=dict(\n",
    "                AMOC26 = ([\"model\", \"time\"], y26N.msftyz.values/DF),\n",
    "                AMOC35 = ([\"model\", \"time\"], y35N.msftyz.values/DF),\n",
    "            ),\n",
    "            coords=dict(\n",
    "                model= new_modsy,\n",
    "                time = y26N.time.values,\n",
    "            ),\n",
    "            attrs=dict(description=\"Dataset with AMOC, zos data.\"),\n",
    "        )\n",
    "    \n",
    "        AMOC = xr.concat([xr_m, xr_y],'model')\n",
    "    \n",
    "    return AMOC\n",
    "\n",
    "def read_amoc_ds_using_velocities(data_dir, mip, sce):\n",
    "    '''\n",
    "    Read both historical and scenario datasets, select the intersecting \n",
    "    models and concatenate the two datasets. This is for AMOC data computed with velocities\n",
    "    '''\n",
    "        \n",
    "    # open data\n",
    "    hist_ds = xr.open_mfdataset(\n",
    "        f'{data_dir}/{mip}_amoc_vo/{mip}_amoc_vo_historical_*.nc')\n",
    "    sce_ds = xr.open_mfdataset(\n",
    "        f'{data_dir}/{mip}_amoc_vo/{mip}_amoc_vo_{sce}_*.nc')\n",
    "            \n",
    "    # see model intersection\n",
    "    model_intersection = list(set(hist_ds.model.values)& set(sce_ds.model.values))\n",
    "    model_intersection.sort()\n",
    "    \n",
    "    #if mip == 'cmip6':\n",
    "    #    model_intersection.remove()\n",
    "\n",
    "    tot_ds = xr.concat([hist_ds,sce_ds],'time').sel(model=model_intersection)\n",
    "    \n",
    "    AMOC = xr.Dataset(\n",
    "            data_vars=dict(\n",
    "                AMOC26 = ([\"model\", \"time\"], tot_ds.sel(latitude=26).amoc.values),\n",
    "                AMOC35 = ([\"model\", \"time\"], tot_ds.sel(latitude=35).amoc.values),\n",
    "            ),\n",
    "            coords=dict(\n",
    "                model= tot_ds.model.values,\n",
    "                time = tot_ds.time.values,\n",
    "            ),\n",
    "            attrs=dict(description=\"Dataset with AMOC, zos data.\"),\n",
    "        )\n",
    "\n",
    "    return AMOC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variable: zos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take average zos over North Sea region:\n",
    "lat_min, lat_max = 51.5, 59.5     \n",
    "lon_min, lon_max = -3.5,  7.5\n",
    "\n",
    "CMIP5_zos = CMIP5_spatial_zos.sel(lat=slice(lat_min,lat_max), lon=slice(lon_min,lon_max)).mean(dim=['lon','lat'])\n",
    "CMIP5_zos = CMIP5_zos.rename({'spatial_zos':'zos'})\n",
    "\n",
    "CMIP6_zos = CMIP6_spatial_zos.sel(lat=slice(lat_min,lat_max), lon=slice(lon_min,lon_max)).mean(dim=['lon','lat'])\n",
    "CMIP6_zos = CMIP6_zos.rename({'spatial_zos':'zos'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variable: GSAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GSAT_CMIP5_list = [[],[],[]]\n",
    "GSAT_CMIP6_list = [[],[],[]]\n",
    "\n",
    "for i, sce in enumerate(['rcp26', 'rcp45', 'rcp85']):\n",
    "    GSAT = tglob_cmip(original_data_dir, 'CMIP5', sce, 1900, 2100.5, LowPass=False)\n",
    "    GSAT = GSAT.assign_coords(time = np.arange(1900.5,2101.5))\n",
    "    GSAT = GSAT.assign_coords({'scenario': sce})\n",
    "    GSAT_CMIP5_list[i]= GSAT\n",
    "\n",
    "for i, sce in enumerate(['ssp126', 'ssp245', 'ssp585']):\n",
    "    GSAT = tglob_cmip(original_data_dir, 'CMIP6', sce, 1900, 2100.5, LowPass=False)\n",
    "    GSAT = GSAT.assign_coords(time = np.arange(1900.5,2101.5))\n",
    "    GSAT = GSAT.assign_coords({'scenario': sce})\n",
    "    GSAT_CMIP6_list[i] = GSAT\n",
    "\n",
    "CMIP5_GSAT = xr.concat(GSAT_CMIP5_list, dim='scenario')\n",
    "CMIP6_GSAT = xr.concat(GSAT_CMIP6_list, dim='scenario')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variable: GMTSL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GMTSL_CMIP5_list = [[],[],[]]\n",
    "GMTSL_CMIP6_list = [[],[],[]]\n",
    "\n",
    "for i, sce in enumerate(['rcp26', 'rcp45', 'rcp85']):\n",
    "    GMTSL = read_zostoga_ds(original_data_dir, 'cmip5', sce)\n",
    "    GMTSL = GMTSL.sel(time=slice(1900,2101))\n",
    "    GMTSL = GMTSL.assign_coords({'scenario': sce})\n",
    "    GMTSL = GMTSL.rename({'zostoga_corrected': 'GMTSL'})\n",
    "    GMTSL_CMIP5_list[i] = GMTSL\n",
    "\n",
    "for i, sce in enumerate(['ssp126', 'ssp245', 'ssp585']):\n",
    "    GMTSL = read_zostoga_ds(original_data_dir, 'cmip6', sce)\n",
    "    GMTSL = GMTSL.sel(time=slice(1900,2101))\n",
    "    GMTSL = GMTSL.assign_coords({'scenario': sce})\n",
    "    GMTSL = GMTSL.rename({'zostoga_corrected': 'GMTSL'})\n",
    "\n",
    "    GMTSL_CMIP6_list[i] = GMTSL\n",
    "\n",
    "CMIP5_GMTSL = xr.concat(GMTSL_CMIP5_list, dim='scenario').drop('trend_picontrol')\n",
    "CMIP6_GMTSL = xr.concat(GMTSL_CMIP6_list, dim='scenario').drop('trend_picontrol')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variable: AMOC26 & AMOC35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AMOC_CMIP5_list = [[],[],[]]\n",
    "AMOC_CMIP6_list = [[],[],[]]\n",
    "\n",
    "for i, sce in enumerate(['rcp26', 'rcp45', 'rcp85']):\n",
    "    amoc_s = read_amoc_ds_using_streamfunction(original_data_dir, 'cmip5', sce)\n",
    "    amoc_v = read_amoc_ds_using_velocities(original_data_dir, 'cmip5', sce)\n",
    "\n",
    "    AMOC = xr.concat([amoc_s,amoc_v],dim='model')\n",
    "    AMOC = AMOC.sel(time=slice(1900,2101))\n",
    "\n",
    "    AMOC = AMOC.assign_coords(time = np.arange(1900.5,2101.5))\n",
    "    AMOC = AMOC.assign_coords({'scenario': sce})\n",
    "\n",
    "    AMOC_CMIP5_list[i]= AMOC\n",
    "\n",
    "for i, sce in enumerate(['ssp126', 'ssp245', 'ssp585']):\n",
    "    amoc_s = read_amoc_ds_using_streamfunction(original_data_dir, 'cmip6', sce)\n",
    "    amoc_v = read_amoc_ds_using_velocities(original_data_dir, 'cmip6', sce)\n",
    "\n",
    "    AMOC = xr.concat([amoc_s,amoc_v],dim='model')\n",
    "    AMOC = AMOC.sel(time=slice(1900,2101))\n",
    "\n",
    "    AMOC = AMOC.assign_coords(time = np.arange(1900.5,2101.5))\n",
    "    AMOC = AMOC.assign_coords({'scenario': sce})\n",
    "    AMOC_CMIP6_list[i] = AMOC\n",
    "\n",
    "CMIP5_AMOC = xr.concat(AMOC_CMIP5_list, dim='scenario')\n",
    "CMIP6_AMOC = xr.concat(AMOC_CMIP6_list, dim='scenario')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenate all variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CMIP5_time_series = xr.merge([CMIP5_zos, CMIP5_GSAT, CMIP5_GMTSL, CMIP5_AMOC])\n",
    "CMIP6_time_series = xr.merge([CMIP6_zos, CMIP6_GSAT, CMIP6_GMTSL, CMIP6_AMOC])\n",
    "\n",
    "# Only select models with zos data available:\n",
    "models_zos5 = CMIP5_time_series['zos'].dropna('model','all').model.values\n",
    "models_zos6 = CMIP6_time_series['zos'].dropna('model','all').model.values\n",
    "\n",
    "CMIP5_time_series = CMIP5_time_series.sel(model=models_zos5)\n",
    "CMIP6_time_series = CMIP6_time_series.sel(model=models_zos6)\n",
    "\n",
    "CMIP5_time_series = CMIP5_time_series - CMIP5_time_series.sel(time=slice(standard_reference_period[0],standard_reference_period[1])).mean(dim='time')\n",
    "CMIP6_time_series = CMIP6_time_series - CMIP6_time_series.sel(time=slice(standard_reference_period[0],standard_reference_period[1])).mean(dim='time')\n",
    "\n",
    "CMIP5_time_series.to_netcdf(write_data_to_dir+'CMIP5_time_series.nc')\n",
    "CMIP6_time_series.to_netcdf(write_data_to_dir+'CMIP6_time_series.nc')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LOWESS filter for smoothed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CMIP_LOWESS(ds, window, mip):\n",
    "    \n",
    "    frac = window/ds.time.values.shape[0]\n",
    "    \n",
    "    mods = ds.model.values\n",
    "\n",
    "    if mip == 'cmip5':\n",
    "        sces = ['rcp26', 'rcp45', 'rcp85']\n",
    "    elif mip == 'cmip6':\n",
    "        sces = ['ssp126', 'ssp245', 'ssp585']\n",
    "    else:\n",
    "        print('mip not recognized')\n",
    "\n",
    "    LF_data_zos = [[],[],[]]\n",
    "    LF_data_GMTSL = [[],[],[]]\n",
    "    LF_data_GSAT = [[],[],[]]\n",
    "    LF_data_AMOC26 = [[],[],[]]\n",
    "    LF_data_AMOC35 = [[],[],[]]\n",
    "\n",
    "    # Loop over scenario, model, variable:\n",
    "    for i, scen in enumerate(sces):\n",
    "        \n",
    "        #for variab in enumerate['zos','zostoga','GSAT','AMOC26']:\n",
    "            \n",
    "        for mod in mods:\n",
    "\n",
    "            LF_data_zos[i].append(lowess(ds.sel(scenario=scen, model=mod)['zos'].values, \n",
    "                                         ds['time'].values, frac, return_sorted=False))\n",
    "            LF_data_GSAT[i].append(lowess(ds.sel(scenario=scen, model=mod)['GSAT'].values, \n",
    "                           ds['time'].values, frac, return_sorted=False))\n",
    "            LF_data_GMTSL[i].append(lowess(ds.sel(scenario=scen, model=mod)['GMTSL'].values, \n",
    "                           ds['time'].values, frac, return_sorted=False))\n",
    "\n",
    "            LF_data_AMOC26[i].append(lowess(ds.sel(scenario=scen, model=mod)['AMOC26'].values, \n",
    "                           ds['time'].values, frac, return_sorted=False))\n",
    "            LF_data_AMOC35[i].append(lowess(ds.sel(scenario=scen, model=mod)['AMOC35'].values, \n",
    "                           ds['time'].values, frac, return_sorted=False))\n",
    "    \n",
    "    \n",
    "    # Store arrays in ds\n",
    "\n",
    "    if mip == 'cmip5':\n",
    "        descr = 'CMIP5 dataset - LOWESS FILTER - with variables dynamic sea-level (zos), \\\n",
    "                    global mean steric sea-level (zostoga), and global surface air temperature (GSAT), \\\n",
    "                    AMOC strength at 26 degrees (AMOC26) and at 35 degrees (AMOC35)'\n",
    "        \n",
    "    elif mip == 'cmip6':\n",
    "        descr=  'CMIP6 dataset - LOWESS FILTER - with variables dynamic sea-level (zos), \\\n",
    "                    global mean steric sea-level (zostoga), and global surface air temperature (GSAT), \\\n",
    "                    AMOC strength at 26 degrees (AMOC26) and at 35 degrees (AMOC35)'\n",
    "        \n",
    "    ds_LOWESS = xr.Dataset(\n",
    "        data_vars=dict(\n",
    "            zos     =([\"scenario\", \"model\" , \"time\"], LF_data_zos),\n",
    "            GMTSL   =([\"scenario\", \"model\" , \"time\"], LF_data_GMTSL),\n",
    "            GSAT    =([\"scenario\", \"model\" , \"time\"], LF_data_GSAT),\n",
    "            AMOC26  =([\"scenario\", \"model\" , \"time\"], LF_data_AMOC26),\n",
    "            AMOC35  =([\"scenario\", \"model\" , \"time\"], LF_data_AMOC35)\n",
    "        ),\n",
    "        coords=dict(\n",
    "            model   =([\"model\"], mods),\n",
    "            scenario=([\"scenario\"], sces),\n",
    "            time    =([\"time\"], ds['time'].values)\n",
    "        ),\n",
    "            attrs=dict(description=descr),\n",
    "        )\n",
    "        \n",
    "    return ds_LOWESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CMIP5_time_series_smoothed = CMIP_LOWESS(CMIP5_time_series, 10, 'cmip5')\n",
    "CMIP6_time_series_smoothed = CMIP_LOWESS(CMIP6_time_series, 10, 'cmip6')\n",
    "\n",
    "CMIP5_time_series_smoothed = CMIP5_time_series_smoothed - CMIP5_time_series_smoothed.sel(time=slice(standard_reference_period[0],standard_reference_period[1])).mean(dim='time')\n",
    "CMIP6_time_series_smoothed = CMIP6_time_series_smoothed - CMIP6_time_series_smoothed.sel(time=slice(standard_reference_period[0],standard_reference_period[1])).mean(dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CMIP5_time_series_smoothed.to_netcdf(write_data_to_dir+'CMIP5_time_series_smoothed_10yr.nc')\n",
    "CMIP6_time_series_smoothed.to_netcdf(write_data_to_dir+'CMIP6_time_series_smoothed_10yr.nc')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLD data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directly from mlotst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read MLD data and select only the models that have ODSL data available as well.\n",
    "MLD_ds6_mlotst = xr.open_mfdataset(f'{original_data_dir}/cmip6_mlotst_historical/cmip6_mlotst_historical_*.nc')\n",
    "MLD_ds5_mlotst = xr.open_mfdataset(f'{original_data_dir}/cmip5_mlotst_historical/cmip5_mlotst_historical_*.nc')\n",
    "\n",
    "CMIP5_time_series = xr.open_dataset('Data/CMIP5_time_series.nc')\n",
    "CMIP6_time_series = xr.open_dataset('Data/CMIP6_time_series.nc')\n",
    "\n",
    "zos_mods5 = CMIP5_time_series['zos'].dropna('model','all').model.values\n",
    "zos_mods6 = CMIP6_time_series['zos'].dropna('model','all').model.values\n",
    "\n",
    "model_intersection5 = list(set(MLD_ds5_mlotst.model.values) & set(zos_mods5))\n",
    "model_intersection6 = list(set(MLD_ds6_mlotst.model.values) & set(zos_mods6))\n",
    "\n",
    "MLD_ds5 = MLD_ds5_mlotst.sel(model=model_intersection5)\n",
    "zos_ds5 = CMIP5_time_series.sel(model=model_intersection5)\n",
    "MLD_ds6 = MLD_ds6_mlotst.sel(model=model_intersection6)\n",
    "zos_ds6 = CMIP6_time_series.sel(model=model_intersection6)\n",
    "\n",
    "print(f'Number of models with mlotst and zos in CMIP5: {len(MLD_ds5.model.values)}')\n",
    "print(f'Number of models with mlotst and zos in CMIP6: {len(MLD_ds6.model.values)}')\n",
    "\n",
    "# Select right time frame 1985 - 2005 and latitude 40.5-84.5 and rename variable MLD\n",
    "\n",
    "MLD_mlotst_CMIP5 = MLD_ds5.sel(time=slice(1985,2005)).mean(dim='time')\n",
    "MLD_mlotst_CMIP5 = MLD_mlotst_CMIP5.sel(lat=slice(40,85))\n",
    "MLD_mlotst_CMIP5 = MLD_mlotst_CMIP5.rename({'CorrectedReggrided_mlotst':'MLD'})\n",
    "\n",
    "MLD_mlotst_CMIP6 = MLD_ds6.sel(time=slice(1985,2005)).mean(dim='time')\n",
    "MLD_mlotst_CMIP6 = MLD_mlotst_CMIP6.sel(lat=slice(40,85))\n",
    "MLD_mlotst_CMIP6 = MLD_mlotst_CMIP6.rename({'CorrectedReggrided_mlotst':'MLD'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLD_mlotst_CMIP5.to_netcdf('Data/CMIP5_spatial_MLD_mlotst.nc')\n",
    "MLD_mlotst_CMIP6.to_netcdf('Data/CMIP6_spatial_MLD_mlotst.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(2,5, figsize=(20,5))\n",
    "ax = axs.flatten()\n",
    "\n",
    "for i, mod in enumerate(MLD_mlotst_CMIP5.model.values):\n",
    "    im = ax[i].pcolormesh(MLD_mlotst_CMIP5.lon, MLD_mlotst_CMIP5.lat,MLD_mlotst_CMIP5.isel(model=i).MLD, vmin=0, vmax=500)\n",
    "    ax[i].set_title(f'Model: {MLD_mlotst_CMIP5.model.values[i]}')\n",
    "    plt.colorbar(im, ax=ax[i])\n",
    "fig.suptitle('CMIP5 mlotst MLD data',fontsize=(30))\n",
    "fig.tight_layout()\n",
    "\n",
    "\n",
    "fig,axs = plt.subplots(7,5, figsize=(20,12.5))\n",
    "ax = axs.flatten()\n",
    "\n",
    "for i, mod in enumerate(MLD_mlotst_CMIP6.model.values):\n",
    "    im = ax[i].pcolormesh(MLD_mlotst_CMIP6.lon, MLD_mlotst_CMIP6.lat,MLD_mlotst_CMIP6.isel(model=i).MLD, vmin=0, vmax=500)\n",
    "    ax[i].set_title(f'Model: {MLD_mlotst_CMIP6.model.values[i]}')\n",
    "    plt.colorbar(im, ax=ax[i])\n",
    "\n",
    "fig.suptitle('CMIP6 mlotst MLD data',fontsize=(30))\n",
    "fig.tight_layout()\n",
    "\n",
    "fig,axs = plt.subplots(1,2,figsize=(20,6))\n",
    "ax = axs.flatten()\n",
    "\n",
    "im = ax[0].pcolormesh(MLD_mlotst_CMIP5.lon, MLD_mlotst_CMIP5.lat,MLD_mlotst_CMIP5.mean(dim='model').MLD, vmin=0, vmax=500)\n",
    "ax[0].set_title(f'CMIP5 ensemble mean')\n",
    "plt.colorbar(im, ax=ax[0])\n",
    "\n",
    "im = ax[1].pcolormesh(MLD_mlotst_CMIP6.lon, MLD_mlotst_CMIP6.lat,MLD_mlotst_CMIP6.mean(dim='model').MLD, vmin=0, vmax=500)\n",
    "ax[1].set_title(f'CMIP6 ensemble mean')\n",
    "plt.colorbar(im, ax=ax[1])\n",
    "\n",
    "fig.suptitle('Ensemble mean mlotst',fontsize=(30))\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From C. Heuzé et al. (2021)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since only few models have mlotst available for CMIP5, we also include MLD data from the study by C. Heuzé (2021) Antarctic Bottom Water and North Atlantic Deep Water in CMIP6 models, Ocean Science, doi:10.5194/os-17-59-2021, vol 17, pp 59-90."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read MLD data from Heuzé publication. Here, the from Heuze\n",
    "\"\"\"\n",
    "Read all files and assign lon2: lon from 180 to 180 degrees instead of 0 to 360\n",
    "Append the different data sets in: MLD_CM5 and MLD_CM6\n",
    "\"\"\"\n",
    "\n",
    "all_files5 = glob.glob(original_data_dir+\"cmip5_mld_heuze/*.nc\")\n",
    "all_files6 = glob.glob(original_data_dir+\"cmip6_mld_heuze/*.nc\")\n",
    "all_files5 = np.sort(all_files5);\n",
    "all_files6 = np.sort(all_files6);\n",
    "\n",
    "MLD_CM5 = []\n",
    "mods_CM5 = []\n",
    "for i in range(len(all_files5)):\n",
    "    MLD_data = xr.open_mfdataset(all_files5[i])\n",
    "    mod_name = MLD_data.model.values\n",
    "    if mod_name in zos_mods5:\n",
    "        MLD_data = MLD_data.set_coords((\"lat\", \"lon\"))\n",
    "        MLD_data = MLD_data.assign_coords(model=mod_name)\n",
    "        MLD_CM5.append(MLD_data)\n",
    "        mods_CM5.append(mod_name)\n",
    "    else:\n",
    "        print(f'This CMIP5 model does not have ODSL data available: {mod_name}')\n",
    "mods_CM5 = np.transpose(mods_CM5)\n",
    "\n",
    "MLD_CM6 = [] \n",
    "mods_CM6 = []\n",
    "for i in range(len(all_files6)):\n",
    "    MLD_data = xr.open_mfdataset(all_files6[i])\n",
    "    mod_name = all_files6[i][34:-40]    \n",
    "    if mod_name in zos_mods6:\n",
    "        MLD_data = MLD_data.set_coords((\"lat\", \"lon\"))\n",
    "        MLD_data = MLD_data.assign_coords(model=mod_name)\n",
    "        MLD_data = MLD_data.isel(time=0)                      \n",
    "        MLD_CM6.append(MLD_data)\n",
    "        mods_CM6.append(mod_name)\n",
    "    else:\n",
    "        print(f'This CMIP6 model does not have ODSL data available: {mod_name}')\n",
    "        \n",
    "print(f'Number of models with MLD-Heuzé and zos in CMIP5: {len(mods_CM5)}')\n",
    "print(f'Number of models with MLD-Heuzé and zos in CMIP6: {len(mods_CM6)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models in this dataset do not use the same grid however. So we need to regrid to the same grid as for mlotst:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_longitude(ds, name_lon):\n",
    "\n",
    "    ds = ds.assign_coords({name_lon:(((ds[name_lon] + 180 ) % 360) - 180)})\n",
    "    ds = ds.sortby(ds[name_lon])\n",
    "\n",
    "    return ds\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(15,5))\n",
    "\n",
    "mask_ds = xr.open_dataset('Raw_Data/reference_masks.nc')\n",
    "mask_ds = rotate_longitude(mask_ds, 'lon')\n",
    "mask_ds = mask_ds.sel(lat=slice(40,85))\n",
    "\n",
    "plt.pcolormesh(mask_ds.lon, mask_ds.lat, mask_ds.mask);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.cos(np.deg2rad(mask_ds.lat))\n",
    "weights.name = 'weights'\n",
    "\n",
    "# Make a dataset to regrid with xESMF\n",
    "ds_out = xr.Dataset({'lat': (['lat'], mask_ds.lat.values),\n",
    "                     'lon': (['lon'], mask_ds.lon.values)})\n",
    "\n",
    "regridded_Heuze_CMIP5 = []\n",
    "regridded_Heuze_CMIP6 = []\n",
    "\n",
    "for i in range(len(MLD_CM5)):\n",
    "    y_ds = MLD_CM5[i]\n",
    "\n",
    "    try: \n",
    "        reg_method = 'nearest_s2d'\n",
    "        regridder = xe.Regridder(y_ds, ds_out, reg_method, periodic=True)\n",
    "        #print(regridder)\n",
    "    except:\n",
    "        print('fail')\n",
    "\n",
    "    dr_out = regridder(y_ds, keep_attrs=True)\n",
    "    regridded_Heuze_CMIP5.append(dr_out)   \n",
    "\n",
    "for i in range(len(MLD_CM6)):\n",
    "    y_ds = MLD_CM6[i]\n",
    "\n",
    "    try: \n",
    "        reg_method = 'nearest_s2d'\n",
    "        regridder = xe.Regridder(y_ds, ds_out, reg_method, periodic=True)\n",
    "        #print(regridder)\n",
    "    except:\n",
    "        print('fail')\n",
    "\n",
    "    dr_out = regridder(y_ds, keep_attrs=True)\n",
    "    regridded_Heuze_CMIP6.append(dr_out)    \n",
    "\n",
    "MLD_Heuze_regridded_CMIP5 = xr.concat(regridded_Heuze_CMIP5, dim='model')\n",
    "MLD_Heuze_regridded_CMIP6 = xr.concat(regridded_Heuze_CMIP6, dim='model')\n",
    "\n",
    "MLD_Heuze_regridded_CMIP5['MLD'] = xr.where(mask_ds.sel(lat=slice(40,85)).mask == 1, MLD_Heuze_regridded_CMIP5.MLD,  np.nan)\n",
    "MLD_Heuze_regridded_CMIP6['MLD'] = xr.where(mask_ds.sel(lat=slice(40,85)).mask == 1, MLD_Heuze_regridded_CMIP6.MLD,  np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to netcdf\n",
    "MLD_Heuze_regridded_CMIP5.to_netcdf('Data/CMIP5_spatial_MLD_Heuze.nc')\n",
    "MLD_Heuze_regridded_CMIP6.to_netcdf('Data/CMIP6_spatial_MLD_Heuze.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(5,5, figsize=(20,10))\n",
    "ax = axs.flatten()\n",
    "\n",
    "for i, mod in enumerate(MLD_Heuze_regridded_CMIP5.model.values):\n",
    "    im = ax[i].pcolormesh(MLD_Heuze_regridded_CMIP5.lon, MLD_Heuze_regridded_CMIP5.lat,MLD_Heuze_regridded_CMIP5.isel(model=i).MLD, vmin=0, vmax=500)\n",
    "    ax[i].set_title(f'Model: {MLD_Heuze_regridded_CMIP5.model.values[i]}')\n",
    "    plt.colorbar(im, ax=ax[i])\n",
    "fig.suptitle('CMIP5 regridded MLD data',fontsize=(30))\n",
    "fig.tight_layout()\n",
    "\n",
    "\n",
    "fig,axs = plt.subplots(1,5, figsize=(20,2.5))\n",
    "ax = axs.flatten()\n",
    "\n",
    "for i, mod in enumerate(MLD_Heuze_regridded_CMIP6.model.values):\n",
    "    im = ax[i].pcolormesh(MLD_Heuze_regridded_CMIP6.lon, MLD_Heuze_regridded_CMIP6.lat,MLD_Heuze_regridded_CMIP6.isel(model=i).MLD, vmin=0, vmax=500)\n",
    "    ax[i].set_title(f'Model: {MLD_Heuze_regridded_CMIP6.model.values[i]}')\n",
    "    plt.colorbar(im, ax=ax[i])\n",
    "\n",
    "fig.suptitle('CMIP6 regridded MLD data',fontsize=(30))\n",
    "fig.tight_layout()\n",
    "\n",
    "fig,axs = plt.subplots(1,2,figsize=(20,6))\n",
    "ax = axs.flatten()\n",
    "\n",
    "im = ax[0].pcolormesh(MLD_Heuze_regridded_CMIP5.lon, MLD_Heuze_regridded_CMIP5.lat,MLD_Heuze_regridded_CMIP5.mean(dim='model').MLD, vmin=0, vmax=500)\n",
    "ax[0].set_title(f'CMIP5 ensemble mean')\n",
    "plt.colorbar(im, ax=ax[0])\n",
    "\n",
    "im = ax[1].pcolormesh(MLD_Heuze_regridded_CMIP6.lon, MLD_Heuze_regridded_CMIP6.lat,MLD_Heuze_regridded_CMIP6.mean(dim='model').MLD, vmin=0, vmax=500)\n",
    "ax[1].set_title(f'CMIP6 ensemble mean')\n",
    "plt.colorbar(im, ax=ax[1])\n",
    "\n",
    "fig.suptitle('Ensemble mean Heuzé',fontsize=(30))\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate these two sources for MLD (mlotst and Heuze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check double model names\n",
    "# Use mlotst if available, otherwise Heuze\n",
    "\n",
    "double_MLD_models_CMIP5 = list(set(MLD_mlotst_CMIP5.model.values)&set(MLD_Heuze_regridded_CMIP5.model.values))\n",
    "double_MLD_models_CMIP6 = list(set(MLD_mlotst_CMIP6.model.values)&set(MLD_Heuze_regridded_CMIP6.model.values))\n",
    "\n",
    "MLD_Heuze_concat_CMIP5 = MLD_Heuze_regridded_CMIP5.drop_sel(model=double_MLD_models_CMIP5)\n",
    "MLD_Heuze_concat_CMIP6 = MLD_Heuze_regridded_CMIP6.drop_sel(model=double_MLD_models_CMIP6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLD_CMIP5 = xr.concat([MLD_mlotst_CMIP5, MLD_Heuze_concat_CMIP5],dim='model')\n",
    "MLD_CMIP6 = xr.concat([MLD_mlotst_CMIP6, MLD_Heuze_concat_CMIP6],dim='model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLD_CMIP5.to_netcdf('Data/CMIP5_spatial_MLD.nc')\n",
    "MLD_CMIP6.to_netcdf('Data/CMIP6_spatial_MLD.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,2,figsize=(20,6))\n",
    "ax = axs.flatten()\n",
    "\n",
    "im = ax[0].pcolormesh(MLD_CMIP5.lon, MLD_CMIP5.lat,MLD_CMIP5.mean(dim='model').MLD, vmin=0, vmax=500)\n",
    "ax[0].set_title(f'CMIP5 ensemble mean')\n",
    "plt.colorbar(im, ax=ax[0])\n",
    "\n",
    "im = ax[1].pcolormesh(MLD_CMIP6.lon, MLD_CMIP6.lat,MLD_CMIP6.mean(dim='model').MLD, vmin=0, vmax=500)\n",
    "ax[1].set_title(f'CMIP6 ensemble mean')\n",
    "plt.colorbar(im, ax=ax[1])\n",
    "\n",
    "fig.suptitle('Ensemble mean MLD',fontsize=(30))\n",
    "fig.tight_layout()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "firstEnv",
   "language": "python",
   "name": "firstenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
